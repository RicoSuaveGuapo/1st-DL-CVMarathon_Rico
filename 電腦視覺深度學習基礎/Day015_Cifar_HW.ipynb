{"cells":[{"cell_type":"markdown","metadata":{"id":"RXDHfwApGy9y","colab_type":"text"},"source":["## 『本次練習內容』\n","#### 運用這幾天所學觀念搭建一個CNN分類器"]},{"cell_type":"markdown","metadata":{"id":"cER5LN8gGy90","colab_type":"text"},"source":["## 『本次練習目的』\n","  #### 熟悉CNN分類器搭建步驟與原理\n","  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"]},{"cell_type":"code","metadata":{"id":"yRhFXhA_Gy90","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c871f60c-0cab-412c-be0a-75cdfed28d3d","executionInfo":{"status":"ok","timestamp":1591256176093,"user_tz":-480,"elapsed":2679,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["from keras import regularizers\n","from keras.layers import Activation\n","from keras.callbacks import LearningRateScheduler\n","\n","\n","from keras.models import Sequential\n","from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras.datasets import cifar10\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.preprocessing import OneHotEncoder\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\n"}]},{"cell_type":"code","metadata":{"id":"bAkY73OMGy95","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"9345d2ec-5945-45cb-a4f9-5eb6fa3c5a5b","executionInfo":{"status":"ok","timestamp":1591256187053,"user_tz":-480,"elapsed":9998,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","print(x_train.shape) #(50000, 32, 32, 3)\n","print(y_train.shape) #(50000, 1)\n","print(x_test.shape)  #(10000, 32, 32, 3)\n","print(y_test.shape)  #(10000, 1)\n","\n","## Normalize Data\n","def normalize(X_train, X_test):\n","        mean = np.mean(X_train,axis=(0,1,2,3))\n","        std = np.std(X_train, axis=(0, 1, 2, 3))\n","        X_train = (X_train-mean)/(std+1e-7)\n","        X_test = (X_test-mean)/(std+1e-7) \n","        return X_train, X_test, mean, std\n","    \n","    \n","## Normalize Training and Testset    \n","x_train, x_test, mean_train, std_train = normalize(x_train, x_test) "],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"(50000, 32, 32, 3)\n(50000, 1)\n(10000, 32, 32, 3)\n(10000, 1)\n"}]},{"cell_type":"code","metadata":{"id":"iQb5ibUsGy98","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"7db0c405-bdb2-4fca-da8b-bf7f06b23378","executionInfo":{"status":"ok","timestamp":1591256189472,"user_tz":-480,"elapsed":695,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["## OneHot Label 由(None, 1)-(None, 10)\n","## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n","one_hot=OneHotEncoder()\n","y_train=one_hot.fit_transform(y_train).toarray() #OneHotEncoder會轉出scipy.csr_matrix資料結構用.toarray()轉numpy array\n","print(y_train.shape)\n","y_test=one_hot.transform(y_test).toarray()\n","print(y_test.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"(50000, 10)\n(10000, 10)\n"}]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def schduler(epoch, lr):\n","    init_lr= 1e-3\n","\n","    if epoch < 12:\n","        return init_lr\n","    elif epoch >=12 and epoch < 15:\n","        return init_lr /2\n","    elif epoch >= 15 and epoch <20:\n","        return init_lr / 10"]},{"cell_type":"code","metadata":{"id":"uiWQXPXSGy9_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":505},"outputId":"ce69bb8a-cedd-43b8-bb10-0ec6cde074d6","executionInfo":{"status":"ok","timestamp":1591256397478,"user_tz":-480,"elapsed":637,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["\n","l2 = 5e-4\n","callbacks = [\n","    LearningRateScheduler(schduler, verbose=1)\n","]\n","\n","classifier=Sequential()\n","\n","#卷積組合\n","classifier.add(Convolution2D(32, kernel_size=(3,3), \n","                             input_shape = (32, 32, 3), activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n","\n","#'''自己決定MaxPooling2D放在哪裡'''\n","\n","#卷積組合\n","classifier.add(Convolution2D(32, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n","\n","classifier.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#卷積組合 \n","classifier.add(Convolution2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n","\n","#卷積組合 \n","classifier.add(Convolution2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n","\n","\n","#卷積組合 \n","classifier.add(Convolution2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n","\n","#卷積組合 \n","classifier.add(Convolution2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n","\n","#flatten\n","classifier.add(Flatten())\n","\n","#FC\n","classifier.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2)))\n","classifier.add(Dropout(0.5))\n","#輸出\n","classifier.add(Dense(output_dim=10,activation='softmax', kernel_regularizer=regularizers.l2(l2)))\n","classifier.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_25 (Conv2D)           (None, 30, 30, 32)        896       \n_________________________________________________________________\nbatch_normalization_25 (Batc (None, 30, 30, 32)        128       \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 28, 28, 32)        9248      \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 28, 28, 32)        128       \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_27 (Conv2D)           (None, 12, 12, 64)        18496     \n_________________________________________________________________\nbatch_normalization_27 (Batc (None, 12, 12, 64)        256       \n_________________________________________________________________\nconv2d_28 (Conv2D)           (None, 10, 10, 64)        36928     \n_________________________________________________________________\nbatch_normalization_28 (Batc (None, 10, 10, 64)        256       \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 8, 8, 128)         73856     \n_________________________________________________________________\nbatch_normalization_29 (Batc (None, 8, 8, 128)         512       \n_________________________________________________________________\nconv2d_30 (Conv2D)           (None, 6, 6, 128)         147584    \n_________________________________________________________________\nbatch_normalization_30 (Batc (None, 6, 6, 128)         512       \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 4608)              0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 128)               589952    \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 10)                1290      \n=================================================================\nTotal params: 880,042\nTrainable params: 879,146\nNon-trainable params: 896\n_________________________________________________________________\n"}]},{"cell_type":"code","metadata":{"id":"nDYE54JeRWpJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"839bdda4-b4f4-4676-a3ee-427ce6398bdd","executionInfo":{"status":"ok","timestamp":1591256810435,"user_tz":-480,"elapsed":209494,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["#超過兩個就要選categorical_crossentrophy\n","classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","classifier.fit(x_train,y_train,batch_size=128,epochs=20, validation_data=(x_test, y_test), callbacks=callbacks)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"Train on 50000 samples, validate on 10000 samples\nEpoch 1/20\n\nEpoch 00001: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 8s 159us/step - loss: 2.1107 - accuracy: 0.4119 - val_loss: 1.8182 - val_accuracy: 0.4824\nEpoch 2/20\n\nEpoch 00002: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 138us/step - loss: 1.5180 - accuracy: 0.5792 - val_loss: 1.3465 - val_accuracy: 0.6381\nEpoch 3/20\n\nEpoch 00003: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 139us/step - loss: 1.2960 - accuracy: 0.6568 - val_loss: 1.2261 - val_accuracy: 0.6810\nEpoch 4/20\n\nEpoch 00004: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 137us/step - loss: 1.1551 - accuracy: 0.7040 - val_loss: 1.1394 - val_accuracy: 0.7056\nEpoch 5/20\n\nEpoch 00005: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 138us/step - loss: 1.0535 - accuracy: 0.7354 - val_loss: 1.0969 - val_accuracy: 0.7267\nEpoch 6/20\n\nEpoch 00006: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 138us/step - loss: 0.9765 - accuracy: 0.7630 - val_loss: 1.0097 - val_accuracy: 0.7532\nEpoch 7/20\n\nEpoch 00007: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 138us/step - loss: 0.9203 - accuracy: 0.7813 - val_loss: 0.9912 - val_accuracy: 0.7632\nEpoch 8/20\n\nEpoch 00008: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 139us/step - loss: 0.8729 - accuracy: 0.8051 - val_loss: 0.9997 - val_accuracy: 0.7714\nEpoch 9/20\n\nEpoch 00009: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 139us/step - loss: 0.8492 - accuracy: 0.8161 - val_loss: 0.9906 - val_accuracy: 0.7720\nEpoch 10/20\n\nEpoch 00010: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 137us/step - loss: 0.8286 - accuracy: 0.8271 - val_loss: 1.0564 - val_accuracy: 0.7706\nEpoch 11/20\n\nEpoch 00011: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 139us/step - loss: 0.8138 - accuracy: 0.8364 - val_loss: 1.0020 - val_accuracy: 0.7888\nEpoch 12/20\n\nEpoch 00012: LearningRateScheduler setting learning rate to 0.001.\n50000/50000 [==============================] - 7s 139us/step - loss: 0.7981 - accuracy: 0.8468 - val_loss: 1.0285 - val_accuracy: 0.7809\nEpoch 13/20\n\nEpoch 00013: LearningRateScheduler setting learning rate to 0.0005.\n50000/50000 [==============================] - 7s 133us/step - loss: 0.6423 - accuracy: 0.8986 - val_loss: 0.9288 - val_accuracy: 0.8101\nEpoch 14/20\n\nEpoch 00014: LearningRateScheduler setting learning rate to 0.0005.\n50000/50000 [==============================] - 7s 132us/step - loss: 0.5520 - accuracy: 0.9208 - val_loss: 0.9708 - val_accuracy: 0.8057\nEpoch 15/20\n\nEpoch 00015: LearningRateScheduler setting learning rate to 0.0005.\n50000/50000 [==============================] - 7s 131us/step - loss: 0.5133 - accuracy: 0.9287 - val_loss: 0.9820 - val_accuracy: 0.8115\nEpoch 16/20\n\nEpoch 00016: LearningRateScheduler setting learning rate to 0.0001.\n50000/50000 [==============================] - 7s 133us/step - loss: 0.4210 - accuracy: 0.9631 - val_loss: 0.9162 - val_accuracy: 0.8300\nEpoch 17/20\n\nEpoch 00017: LearningRateScheduler setting learning rate to 0.0001.\n50000/50000 [==============================] - 7s 132us/step - loss: 0.3693 - accuracy: 0.9787 - val_loss: 0.9323 - val_accuracy: 0.8285\nEpoch 18/20\n\nEpoch 00018: LearningRateScheduler setting learning rate to 0.0001.\n50000/50000 [==============================] - 7s 133us/step - loss: 0.3437 - accuracy: 0.9838 - val_loss: 0.9446 - val_accuracy: 0.8275\nEpoch 19/20\n\nEpoch 00019: LearningRateScheduler setting learning rate to 0.0001.\n50000/50000 [==============================] - 7s 132us/step - loss: 0.3234 - accuracy: 0.9881 - val_loss: 0.9636 - val_accuracy: 0.8292\nEpoch 20/20\n\nEpoch 00020: LearningRateScheduler setting learning rate to 0.0001.\n50000/50000 [==============================] - 7s 132us/step - loss: 0.3057 - accuracy: 0.9900 - val_loss: 0.9696 - val_accuracy: 0.8266\n"},{"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fb841221990>"},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 4 conv\n","# Epoch 20/20\n","# 50000/50000 [==============================] - 5s 107us/step - loss: 0.2093 - accuracy: 0.9250 - val_loss: 1.0676 - val_accuracy: 0.7571\n","\n","# 6 conv\n","# Epoch 20/20\n","# 50000/50000 [==============================] - 6s 128us/step - loss: 0.1691 - accuracy: 0.9415 - val_loss: 0.8620 - val_accuracy: 0.7954\n","\n","# 6 conv with regularizers\n","# Epoch 20/20\n","# 50000/50000 [==============================] - 7s 131us/step - loss: 1.0214 - accuracy: 0.8168 - val_loss: 1.1655 - val_accuracy: 0.7739\n","\n","# 6 conv with ref and \n"]},{"cell_type":"markdown","metadata":{"id":"qWN8Pk-yGy-B","colab_type":"text"},"source":["## 預測新圖片，輸入影像前處理要與訓練時相同\n","#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n","## 維度如下方示範"]},{"cell_type":"code","metadata":{"id":"eOkXxFixGy-B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"5aa554c1-138a-4d9a-97b9-a8055e848b00","executionInfo":{"status":"ok","timestamp":1591257418827,"user_tz":-480,"elapsed":590,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n","classifier.predict(input_example)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[1.5207659e-04, 2.9897876e-06, 2.3086229e-03, 9.4982153e-01,\n        3.9112419e-02, 5.4175896e-04, 7.2014830e-03, 3.2285438e-06,\n        8.4389967e-04, 1.2011511e-05]], dtype=float32)"},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"CZbE57iiUf3L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"3baf4d9d-9280-4c5f-ee2a-22a1bc046eac","executionInfo":{"status":"ok","timestamp":1591257389298,"user_tz":-480,"elapsed":692,"user":{"displayName":"李彥頲","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYLuy6N0x9fcWjTEPlNKqL6M1uCxO5ZzPgnC9q=s64","userId":"18319664738923439438"}}},"source":["test_img = x_test[0,...]\n","test_img = test_img.reshape(1, test_img.shape[0], test_img.shape[1], test_img.shape[2])\n","test_label = y_test[0]\n","\n","print(test_label)\n","print(classifier.predict(test_img))\n"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n[[1.3463177e-06 5.5094972e-07 5.6494018e-06 9.9960023e-01 6.2131244e-07\n  1.1880239e-04 2.5179121e-04 2.1903136e-06 1.0858335e-05 7.9874062e-06]]\n"}]},{"cell_type":"code","metadata":{"id":"UOirKEIFVNXj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"colab":{"name":"Day015_Cifar_HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}